{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYuafeS8vD7D",
        "outputId": "291d6a1e-5ef4-4da3-a7ad-b81894479820"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/Colab Notebooks"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo4AWr_1wH3a"
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch import Tensor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6UP7egkvh_e",
        "outputId": "0ed30857-57e3-4bd3-88ba-3b91b4db0564"
      },
      "source": [
        "sonido_dic=np.load(\"datasetNuevo/sonidos.npy\",allow_pickle=True).item()\n",
        "print(len(sonido_dic))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH2Jg9orwK3e",
        "outputId": "91ffbdcc-6a63-4e4c-fb94-a0b2cdfe42a1"
      },
      "source": [
        "partituras_dic=np.load(\"datasetNuevo/partituras.npy\",allow_pickle=True).item()\n",
        "print(partituras_dic)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'9.xml': [1, 35, 35, 9, 9, 28, 28, 5, 5, 39, 39, 15, 15, 32, 32, 11, 11, 21, 21, 21, 21, 2], '8.xml': [1, 42, 42, 38, 38, 18, 18, 3, 3, 12, 12, 3, 3, 18, 18, 38, 38, 42, 42, 43, 43, 2], '2.xml': [1, 42, 42, 38, 38, 18, 18, 3, 3, 12, 12, 3, 3, 18, 18, 38, 38, 42, 42, 43, 43, 2], '7.xml': [1, 21, 21, 11, 11, 32, 32, 15, 15, 39, 39, 5, 5, 28, 28, 9, 9, 35, 35, 43, 43, 2], '1.xml': [1, 21, 21, 11, 11, 32, 32, 15, 15, 39, 39, 5, 5, 28, 28, 9, 9, 35, 35, 43, 43, 2], '4.xml': [1, 21, 21, 11, 11, 32, 32, 15, 15, 39, 39, 5, 5, 28, 28, 9, 9, 35, 35, 43, 43, 2], '3.xml': [1, 35, 35, 9, 9, 28, 28, 5, 5, 39, 39, 15, 15, 32, 32, 11, 11, 21, 21, 21, 21, 2], '6.xml': [1, 35, 35, 9, 9, 28, 28, 5, 5, 39, 39, 15, 15, 32, 32, 11, 11, 21, 21, 21, 21, 2], 'boqueron.xml': [1, 7, 20, 6, 20, 6, 24, 41, 33, 30, 29, 34, 16, 10, 8, 36, 29, 22, 25, 17, 7, 20, 6, 20, 6, 24, 41, 33, 30, 29, 34, 16, 10, 8, 36, 29, 22, 25, 17, 31, 31, 34, 22, 4, 14, 13, 29, 27, 29, 16, 26, 14, 13, 24, 37, 40, 23, 31, 31, 34, 22, 4, 14, 13, 29, 27, 29, 16, 26, 14, 13, 24, 37, 40, 23, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2], '5.xml': [1, 42, 42, 38, 38, 18, 18, 3, 3, 12, 12, 3, 3, 18, 18, 38, 38, 42, 42, 43, 43, 2]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8x14i5owmOa",
        "outputId": "8837c120-a2b6-425b-b861-1aac52a6f4d0"
      },
      "source": [
        "with open(\"datasetNuevo/vocabulario2.json\", \"r\") as fp:\n",
        "        vocabPart = json.load(fp)\n",
        "\n",
        "vocabPart"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'60 2.0 None': 21,\n",
              " '62 2.0 None': 11,\n",
              " '64 2.0 None': 32,\n",
              " '65 2.0 None': 15,\n",
              " '67 0.25 None': 7,\n",
              " '67 1.0 start': 40,\n",
              " '67 1.0 stop': 23,\n",
              " '67 2.0 None': 39,\n",
              " '69 0.25 None': 20,\n",
              " '69 0.5 None': 37,\n",
              " '69 2.0 None': 5,\n",
              " '71 0.25 None': 24,\n",
              " '71 0.25 start': 14,\n",
              " '71 0.25 stop': 13,\n",
              " '71 0.5 None': 6,\n",
              " '71 0.75 None': 4,\n",
              " '71 1.0 start': 25,\n",
              " '71 1.0 stop': 17,\n",
              " '71 2.0 None': 28,\n",
              " '72 2.0 None': 9,\n",
              " '74 0.5 None': 22,\n",
              " '74 2.0 None': 35,\n",
              " '75 0.25 None': 27,\n",
              " '75 0.5 None': 26,\n",
              " '76 0.25 None': 29,\n",
              " '76 0.25 start': 8,\n",
              " '76 0.25 stop': 36,\n",
              " '76 0.5 None': 34,\n",
              " '76 1.0 start': 33,\n",
              " '76 1.0 stop': 30,\n",
              " '76 2.0 None': 43,\n",
              " '77 2.0 None': 42,\n",
              " '78 0.25 None': 16,\n",
              " '79 0.5 None': 31,\n",
              " '79 0.75 None': 10,\n",
              " '79 1.0 None': 41,\n",
              " '79 2.0 None': 38,\n",
              " '81 2.0 None': 18,\n",
              " '83 2.0 None': 3,\n",
              " '84 2.0 None': 12,\n",
              " '<eos>': 2,\n",
              " '<pad>': 0,\n",
              " '<sos>': 1,\n",
              " 'r 1.0 stop': 19}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoCfkGJ_aDng"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import  DataLoader\n",
        "import numpy as np\n",
        "def cargaDatos():\n",
        "    data=[]\n",
        "    sonido_dic=np.load(\"datasetNuevo/sonidos.npy\",allow_pickle=True).item()\n",
        "    partituras_dic=np.load(\"datasetNuevo/partituras.npy\",allow_pickle=True).item()\n",
        "    \n",
        "    for sonido in sonido_dic:\n",
        "        for part in partituras_dic:\n",
        "            if part[:-4]==sonido[:-4]:\n",
        "                audio=torch.tensor(sonido_dic[sonido],dtype=torch.float64)\n",
        "                partitura=torch.tensor(partituras_dic[part])\n",
        "                data.append((audio,partitura))\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7G71Hjj8dTw"
      },
      "source": [
        "def generate_batch(data_batch):\n",
        "    audio_batch, partitura_batch = [], []\n",
        "    for (audio, partitura) in data_batch:\n",
        "        audio_batch.append(torch.cat([torch.tensor([1]), audio, torch.tensor([2])], dim=0))\n",
        "        partitura_batch.append( partitura)\n",
        "    audio_batch = pad_sequence(audio_batch, padding_value=0)\n",
        "    partitura_batch = pad_sequence(partitura_batch, padding_value=0)\n",
        "    \n",
        "    print(partitura_batch.shape,audio_batch.shape)\n",
        "    return audio_batch, partitura_batch"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z8BNVup9tQ8",
        "outputId": "0051cc87-7170-4cd6-f713-ab33fb2ed9d8"
      },
      "source": [
        "\n",
        "BATCH_SIZE = 3\n",
        "PAD_IDX = vocabPart['<pad>']\n",
        "SOS_IDX = vocabPart['<sos>']\n",
        "EOS_IDX = vocabPart['<eos>']\n",
        "\n",
        "print(PAD_IDX)\n",
        "print(SOS_IDX)\n",
        "print(EOS_IDX)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ_nNlvD8gIJ",
        "outputId": "6f7a2b97-8eb4-44b2-c8ad-e1b260d9e910"
      },
      "source": [
        "muestra= cargaDatos()\n",
        "train_dataset= DataLoader(muestra,batch_size=BATCH_SIZE,collate_fn=generate_batch,shuffle=True)\n",
        "x ,y=next(iter(train_dataset))\n",
        "print(x.shape)\n",
        "print(x)\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([22, 3]) torch.Size([9986, 3])\n",
            "torch.Size([9986, 3])\n",
            "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
            "        [5.5741e+00, 5.5741e+00, 1.2859e+00],\n",
            "        [1.6378e+00, 1.6378e+00, 1.1554e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 2.0090e-06],\n",
            "        [0.0000e+00, 0.0000e+00, 9.3739e-06],\n",
            "        [0.0000e+00, 0.0000e+00, 2.0000e+00]], dtype=torch.float64)\n",
            "torch.Size([22, 3])\n",
            "tensor([[ 1,  1,  1],\n",
            "        [42, 42, 35],\n",
            "        [42, 42, 35],\n",
            "        [38, 38,  9],\n",
            "        [38, 38,  9],\n",
            "        [18, 18, 28],\n",
            "        [18, 18, 28],\n",
            "        [ 3,  3,  5],\n",
            "        [ 3,  3,  5],\n",
            "        [12, 12, 39],\n",
            "        [12, 12, 39],\n",
            "        [ 3,  3, 15],\n",
            "        [ 3,  3, 15],\n",
            "        [18, 18, 32],\n",
            "        [18, 18, 32],\n",
            "        [38, 38, 11],\n",
            "        [38, 38, 11],\n",
            "        [42, 42, 21],\n",
            "        [42, 42, 21],\n",
            "        [43, 43, 21],\n",
            "        [43, 43, 21],\n",
            "        [ 2,  2,  2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swNYVuwGxHIS"
      },
      "source": [
        "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
        "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
        "\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
        "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
        "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "                \n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
        "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
        "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
        "                                        tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZOuSSwy78OZ"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 10000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(20000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + \n",
        "                            self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3vUqYtnB3eM"
      },
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KbCy6_yGIds",
        "outputId": "c52ea03d-aa63-4cb2-c88a-a769ddff4ab0"
      },
      "source": [
        "tensorP =TokenEmbedding(vocab_size=len(vocabPart),emb_size=512)\n",
        "tensorP"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TokenEmbedding(\n",
              "  (embedding): Embedding(44, 512)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "EXo53tyxHBmg",
        "outputId": "f945ed75-d035-44cc-b394-5ab80fd76b15"
      },
      "source": [
        "prueba=tensorP(x)\n",
        "prueba"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9710a59e9d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprueba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-012d43ea6f05>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.embedding(\n\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNL8HGFo8Aqx"
      },
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "  src_seq_len = src.shape[0]\n",
        "  tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_ULcdRaBg8i",
        "outputId": "96ceba7d-e0c4-4d53-ddc8-c520864a8160"
      },
      "source": [
        "m= generate_square_subsequent_mask(42)\n",
        "m.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([42, 42])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwVzeZLpCIJp"
      },
      "source": [
        "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask=create_mask(x,y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSSdp0-bD1MO",
        "outputId": "ce5740b9-22f5-44f8-f7f8-fa10a14a1702"
      },
      "source": [
        "print(src_mask.shape)\n",
        "print(src_mask)\n",
        "print(tgt_mask.shape)\n",
        "print(tgt_mask)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([9986, 9986])\n",
            "tensor([[False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        ...,\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False]])\n",
            "torch.Size([22, 22])\n",
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdwYqRTAC2Js",
        "outputId": "37116169-1410-4d3b-bbe8-b85f29330d00"
      },
      "source": [
        "print(src_padding_mask.shape)\n",
        "print(src_padding_mask)\n",
        "print(tgt_padding_mask.shape)\n",
        "print(tgt_padding_mask)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 9986])\n",
            "tensor([[False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ..., False, False, False]])\n",
            "torch.Size([3, 22])\n",
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en4HnSD-Z9XN"
      },
      "source": [
        "SRC_VOCAB_SIZE = x.shape[0]\n",
        "TGT_VOCAB_SIZE = len(vocabPart)\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 6\n",
        "NUM_DECODER_LAYERS = 6\n",
        "NUM_EPOCHS = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQc0Q_fc_Hwb"
      },
      "source": [
        "\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
        "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
        "                                 FFN_HID_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIahwlUiB6gZ"
      },
      "source": [
        "print(transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5H1k-tQCkwf"
      },
      "source": [
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XISvCYNdDOHj"
      },
      "source": [
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKYlo1QLDQSl"
      },
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lolwoKBDD6jT"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'El modelo tiene {count_parameters(transformer):,} parametros entrenables')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrdLz9SuEwgJ"
      },
      "source": [
        "def train_epoch(model, train_iter, optimizer):\n",
        "  model.train()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in enumerate(train_iter):\n",
        "      src = src.to(device)\n",
        "      tgt = tgt.to(device)\n",
        "            \n",
        "      tgt_input = tgt[:-1, :]\n",
        "\n",
        "      src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "      logits = model(src, tgt_input, src_mask, tgt_mask,\n",
        "                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      tgt_out = tgt[1:,:]\n",
        "      loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      losses += loss.item()\n",
        "  return losses / len(train_iter)\n",
        "\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "  model.eval()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in (enumerate(valid_iter)):\n",
        "    src = src.to(device)\n",
        "    tgt = tgt.to(device)\n",
        "\n",
        "    tgt_input = tgt[:-1, :]\n",
        "\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "    logits = model(src, tgt_input, src_mask, tgt_mask,\n",
        "                              src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "    tgt_out = tgt[1:,:]\n",
        "    loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "    losses += loss.item()\n",
        "  return losses / len(val_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D974imm5Fh5y"
      },
      "source": [
        "import io\n",
        "import time\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "  start_time = time.time()\n",
        "  train_loss = train_epoch(transformer, train_dataset, optimizer)\n",
        "  end_time = time.time()\n",
        "  \n",
        "  print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: , \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYZj5lIoFB_W"
      },
      "source": [
        "import io\n",
        "import time\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "  start_time = time.time()\n",
        "  train_loss = train_epoch(transformer, train_iter, optimizer)\n",
        "  end_time = time.time()\n",
        "  val_loss = evaluate(transformer, valid_iter)\n",
        "  print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}